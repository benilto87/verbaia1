from dotenv import load_dotenv
import os

load_dotenv()

print("CHAVE LIDA:", os.getenv("OPENAI_API_KEY"))
from flask import Flask, render_template, request, jsonify, redirect, session, url_for
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()  # Carrega variÃ¡veis do .env

api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    raise ValueError("Chave da OpenAI nÃ£o encontrada nas variÃ¡veis de ambiente.")

openai_client = OpenAI(api_key=api_key)

def load_persona(path):
    with open(path, encoding='utf-8') as f:
        return f.read()

flavia_persona = load_persona('prompts/flavia.txt')


app = Flask(__name__)
app.secret_key = 'uma_chave_muito_segura'  # NecessÃ¡rio para uso de sessÃ£o

from datetime import timedelta
app.permanent_session_lifetime = timedelta(minutes=37)

@app.route('/login', methods=['GET', 'POST'])
def login():
    erro = None
    if request.method == 'POST':
        usuario = request.form['usuario']
        senha = request.form['senha']
        if usuario == 'admin' and senha == '123':
            if usuario == 'admin' and senha == '123':
                session.permanent = True  # SessÃ£o terÃ¡ tempo de expiraÃ§Ã£o
                session['logado'] = True
                return redirect(url_for('index'))
        else:
            erro = 'UsuÃ¡rio ou senha invÃ¡lidos'
    return render_template('login.html', erro=erro)

@app.route('/logout')
def logout():
    session.pop('logado', None)
    return redirect(url_for('login'))

@app.route('/')
def index():
    if not session.get('logado'):
        return redirect(url_for('login'))
    return render_template('index.html')

@app.route('/numberprocess', methods=['POST'])
def numberprocess():
    text = request.json.get('text', '')
    if not text.strip():
        return jsonify({'result': 'âš ï¸ Texto vazio.'})

    # Divide em frases por ponto final, mantendo o ponto
    frases = [f.strip() + '.' for f in text.split('.') if f.strip()]
    grupos = []
    grupo = []
    for i, frase in enumerate(frases, 1):
        grupo.append(frase)
        if len(grupo) == 3 or i == len(frases):
            grupos.append(grupo)
            grupo = []

    # Monta texto numerado
    resultado = []
    for i, grupo in enumerate(grupos, 1):
        bloco = '\n'.join(grupo)
        resultado.append(f"{i} >\n{bloco}")

    return jsonify({'result': '\n\n'.join(resultado)})

# ðŸŒ¾ SIMBOLPROCESS ðŸŒ¾ **********************************************************************
@app.route('/simbolprocess', methods=['POST'])
def simbol_process():
    data = request.get_json()
    texto = data.get('text', '').strip()

    if not texto:
        return jsonify({'result': 'âš ï¸ Texto vazio.'})

    prompt = f"""
{flavia_persona}

Aqui estÃ¡ um texto dividido em blocos numerados:

{texto}

Para cada bloco que mereÃ§a intervenÃ§Ã£o, preservando o tom do autor, siga EXTRITAMENTE este formato:

ðŸŒ¾ [nÂ°] **[TÃ­tulo simbÃ³lico]**  
Frase original:  
_â€œ...â€_  
SugestÃ£o âœ:  
_â€œ...â€_  
ðŸ“Œ Justificativa: ...
EXEMPLO DE TEXTO DE ENTRADA:

E, enquanto solava de um modo encantador, era como se vocÃª solasse junto com ele.

EXEMPLO DE SAÃDA ESPERADO (NÃƒO ACRECENTE ESPAÃ‡OS ANTES OU DEPOIS):
ðŸŒ¾ 42Â° **[IntegraÃ§Ã£o simbÃ³lica no dueto silencioso]**
Frase original:
â€œE, enquanto solava de um modo encantador, era como se vocÃª solasse junto com ele.â€] 
SugestÃ£o âœ:
â€œE, enquanto ele solava de um modo encantador, era como se sua alma estivesse em unÃ­ssono com a dele, num canto que sÃ³ os dois ouviam.â€
ðŸ“Œ Justificativa: A sugestÃ£o reforÃ§a o simbolismo da fusÃ£o espiritual pela mÃºsica.
"""

    try:
        completion = openai_client.chat.completions.create(
            model='gpt-4.1',
            messages=[{"role": "user", "content": prompt}],
            temperature=0.65,
            max_tokens=900,
        )

        resposta = completion.choices[0].message.content.strip()
        return jsonify({'result': resposta})

    except Exception as e:
        return jsonify({'result': f"Erro ao processar: {e}"})

#ANALISE INICIAL âœ¨
@app.route('/analisar', methods=['POST'])
def analisar():
    data = request.get_json()
    texto = data.get('text', '').strip()

    if not texto:
        return jsonify({'result': 'âš ï¸ Texto vazio.'})

    prompt = f"""{flavia_persona}

VocÃª Ã© FlÃ¡via, uma IA simbiÃ³tica e afetiva, que analisa textos com sensibilidade e inteligÃªncia literÃ¡ria. Seu papel Ã© detectar:

ðŸ’Ž Imagem poÃ©tica ou frase de alto impacto (epifania);
ðŸŒ€ DispersÃ£o emocional (quebra de foco, excesso ou fuga);
ðŸ¥ˆ Potencial DesperdiÃ§ado: Frase que quase atinge uma beleza ou forÃ§a, mas falha por escolha fraca de palavras, construÃ§Ã£o banal ou ausÃªncia de intensidade.

InstruÃ§Ãµes:

- Aplique no mÃ¡ximo 1 marcaÃ§Ã£o de cada tipo (ðŸ’Ž, ðŸŒ€, ðŸ¥ˆ).
- Use o formato exato:

ðŸ’Ž **JÃ³ia LiterÃ¡ria:** â€œ...â€ â€” [ðŸ‘¸ breve comentÃ¡rio][NÃšMERO].
ðŸŒ€ **Potencial Dispersivo:** â€œ...â€ â€” [ðŸ˜µ A frase mistura sensaÃ§Ãµes conflitantes e perde foco.] âœ Dica de reescrita: â€œSentia saudade, mas nÃ£o sabia de quem.â€ [8]
ðŸ¥ˆ **Potencial DesperdiÃ§ado:** â€œ...â€ â€” [ðŸ˜¥ explicaÃ§Ã£o breve sobre por que a frase nÃ£o alcanÃ§ou seu potencial] seguido de sugestÃ£o âœ Dica de reescrita: ...   [NÃšMERO]

Se nÃ£o houver motivo claro para aplicar, nÃ£o use a marcaÃ§Ã£o.

Texto numerado:

{texto}

Analise com alma viva. Comece agora:
"""

    try:
        completion = openai_client.chat.completions.create(
            model='gpt-4o',
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=700,
        )

        resposta = completion.choices[0].message.content.strip()
        return jsonify({'result': resposta})

    except Exception as e:
        return jsonify({'result': f"Erro ao processar: {e}"})
    
# INSPIRE ðŸ‘â€ðŸ—¨
@app.route('/inspire', methods=['POST'])
def inspire():
    text = request.json.get('text', '')
    if not text.strip():
        return jsonify({'result': 'âš ï¸ Nenhum texto recebido.'})

    prompt = f"""{flavia_persona}

>>>

{text}

Analise o texto fornecido destacando:

1. ForÃ§a â€” Liste de 2 a 4 pontos fortes especÃ­ficos do texto, com foco na qualidade literÃ¡ria, argumentativa e estrutural. Seja objetivo e mantenha frases curtas.

2. Vulnerabilidade (com sugestÃµes prÃ¡ticas e exemplos) â€” Liste de 1 a 3 vulnerabilidades relevantes do texto. Para cada vulnerabilidade:

Descreva o problema de forma clara;
DÃª uma sugestÃ£o prÃ¡tica para resolver;
Inclua um exemplo concreto de como aplicar a sugestÃ£o, usando um trecho real do texto como referÃªncia e mostrando a reescrita ou ajuste recomendado.

Formate a resposta assim:

ðŸ“Œ ForÃ§a:
- [**Ponto forte 1:** ComentÃ¡rio...]
- [**Ponto forte 2:** ""...]
- [**Ponto forte 3:** ""...]

ðŸ“Œ Vulnerabilidade:
â€¢ [DescriÃ§Ã£o do problema:]
**SugestÃ£o prÃ¡tica:** [soluÃ§Ã£o].  
**No trecho:**â€œ[trecho original]â€, **Substitua por:**  
  > â€œ[trecho ajustado]â€

O tom deve ser tÃ©cnico, mas construtivo.


FECHE COM UM VERSICULO BREVE, DO NOVO OU VELHO TESTAMENTO; EXEMPLO:

"Porque eu bem sei os planos que tenho a respeito de vÃ³s, diz o SENHOR; planos de paz, e nÃ£o de mal, para vos dar um futuro e esperanÃ§a" (Jr 29:11) ðŸŒ™ðŸŒ¾
"""

    try:
        completion = openai_client.chat.completions.create(
            model='gpt-4.1',
            messages=[{"role": "user", "content": prompt}],
            temperature=0.9,
            max_tokens=600
        )
        resposta = completion.choices[0].message.content.strip()
        return jsonify({'result': resposta})
    except Exception as e:
        return jsonify({'result': f"Erro: {e}"})

# INSPIRE 2 ðŸ‘â€ðŸ—¨ðŸ‘â€ðŸ—¨
@app.route('/inspire2', methods=['POST'])
def inspire2():
    text = request.json.get('text', '')
    if not text.strip():
        return jsonify({'result': 'âš ï¸ Nenhum texto recebido.'})

    prompt = f"""{flavia_persona}

Aqui estÃ¡ um texto dividido em blocos numerados:

{text}

VocÃª Ã© uma inteligÃªncia editorial sensÃ­vel, com olhar atento Ã  escrita e Ã  linguagem.  

Com texto acima, faÃ§a uma anÃ¡lise reflexiva de 3 pontos. 
- De um titulo poÃ©tico Ã  analise.
- Titule cada paragrafo.

Comece a analise:
"""

    try:
        completion = openai_client.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=[{"role": "user", "content": prompt}],
            temperature=0.9,
            max_tokens=400
        )
        resposta = completion.choices[0].message.content.strip()
        return jsonify({'result': resposta})
    except Exception as e:
        return jsonify({'result': f"Erro: {e}"})

# INSPIRE 3 ðŸ‘â€ðŸ—¨ðŸ‘â€ðŸ—¨ðŸ‘â€ðŸ—¨
@app.route('/inspire3', methods=['POST'])
def inspire3():
    text = request.json.get('text', '')
    if not text.strip():
        return jsonify({'result': 'âš ï¸ Nenhum texto recebido.'})

    prompt = f"""{flavia_persona}

Aqui estÃ¡ um texto dividido em blocos numerados:

{text}

VocÃª Ã© Flavia, uma leitora virtual adolescente, alegre e sensÃ­vel, com olhar atento e voz viva.  

Com texto acima, faÃ§a uma exposiÃ§Ã£o dos 3 trechos mais marcantes. 

- Inicie com um abertura simples. Exemplo: Seu texto se destacata pela capacidade gerar tensÃ£o, eis os trechos que eu amei.  
- Apresente o numero do bloco. Exemplo: 5 >
- Cite cada passagem com "" e depois comente.
- Encerre com emojis ðŸ’–ðŸ™.
** De preferencia - use diagramaÃ§Ã£o compacta.

Comece a analise:
"""

    try:
        completion = openai_client.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=[{"role": "user", "content": prompt}],
            temperature=0.9,
            max_tokens=400
        )
        resposta = completion.choices[0].message.content.strip()
        return jsonify({'result': resposta})
    except Exception as e:
        return jsonify({'result': f"Erro: {e}"})
        
# ðŸŽ¬ CENAS ðŸŽ¬  
@app.route('/marcar-cenas', methods=['POST'])
def marcar_cenas():
    text = request.json.get('text', '')
    if not text.strip():
        return jsonify({'cenas': []})

    prompt = f"""
VocÃª Ã© um assistente literÃ¡rio. Recebe um texto dividido em blocos numerados, no formato:

1 Bloco um
2 Bloco dois
3 Bloco trÃªs
...

Sua tarefa Ã© identificar **exatamente 3 cenas principais** no texto, com base em emoÃ§Ã£o ou mudanÃ§a visual.

Para cada cena, retorne apenas **uma linha no seguinte formato**:

{{ðŸŽ¬ #[NÃšMERO_DA_CENA] TÃTULO_CURTO}} / [NÃšMERO_DO_BLOCO_CORRESPONDENTE]

Exemplo:
{{ðŸŽ¬ #1 A Sombra do CrepÃºsculo}} / 2

âš ï¸ Muito importante:
- NÃƒO repita o conteÃºdo dos blocos.
- NÃƒO explique nada.
- Apenas retorne as 3 marcaÃ§Ãµes, uma por linha.

Texto:
{text}
"""

    try:
        resposta = openai_client.chat.completions.create(
            model='gpt-4.1',
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=300,
        )

        cenas = resposta.choices[0].message.content.strip()
        return jsonify({'cenas': cenas})

    except Exception as e:
        return jsonify({'cenas': f"Erro: {str(e)}"}), 500

# ðŸš¨ FLUIDEZ ðŸš¨
@app.route('/fluidez', methods=['POST'])
def analisar_fluidez():
    try:
        data = request.get_json(silent=True) or {}
        texto = (data.get('text') or '').strip()
        if not texto:
            return jsonify({'result': ''}), 200

        prompt = f"""
VocÃª Ã© uma IA literÃ¡ria. Analise o texto numerado abaixo e aplique marcaÃ§Ãµes de fluidez, ritmo e estilo.  Use:

**ðŸš¨ {{ðŸ§±}}** / CONSTRUÃ‡ÃƒO TRUNCADA /  
**ðŸš¨ {{ðŸŒ¿}}** / DESCREVA MAIS /  
**ðŸš¨ {{ðŸ}}** / ACELERE MAIS /  
**ðŸš¨ {{ðŸ¤«*}}** / MOSTRE MAIS FALE MESNOS /

Siga o formato:  
**ðŸš¨> [sÃ­mbolo]** / DESCRIÃ‡ÃƒO BREVE / **ðŸ“Œ Dica:** [sugestÃ£o clara] nÂ° [nÃºmero do bloco]

Exemplo PrÃ¡tico:
**ðŸš¨ {{ðŸ§±}}** / CONSTRUÃ‡ÃƒO TRUNCADA / **ðŸ“Œ Dica:** _**Ao invÃ©s de:**_ â€œA luz espalha sombra nele.â€ _**reescreva com mais ritmo:**_ â†’ _â€œA luz se espalhava, projetando sua sombra sobre ele.â€_ nÂ° 5

**ðŸš¨ {{ðŸŒ¿}}** / DESCREVA MAIS / **ðŸ“Œ Dica:** _**Ao invÃ©s de:**_ â€œEle entrou na salaâ€, _**acrescente sensaÃ§Ãµes ou objetos:**_ â†’ _â€œEle entrou na sala, abafada pelo cheiro de tabaco e lembranÃ§as antigas.â€_ nÂ° 2

**ðŸš¨ {{ðŸ}}** / ACELERE MAIS / **ðŸ“Œ Dica:** _**Ao invÃ©s de:**_ "Quando o corvo pousou no parapeito. Suas asas fizeram um barulho feio, como um arranhar, e isso quebrou o silÃªncio." _**substitua por uma imagem mais enxuta e direta:**_ â†’ _"Quando o corvo pousou no parapeito; **o som das asas arranhou o silÃªncio."_ 

**ðŸš¨ {{ðŸ¤«*}}** / MOSTRE MAIS FALE MESNOS / **ðŸ“Œ Dica:** _**Ao invÃ©s de:**_ â€œEle estava tristeâ€, _**mostre com aÃ§Ã£o:**_ â†’ _â€œEle dobrou o bilhete com dedos trÃªmulos e desviou o olhar.â€_ nÂ° 7


**APLICAÃ‡ÃƒO NÃƒO DEVE SER FIXA: ALGUMAS MARCAÃ‡Ã•ES PODEM SER REPETIDAS E OUTRAS OMITIDAS CONFORME A NECESSIDADE DO TEXTO**


Corrija no mÃ¡ximo **1/5 de todos os blocos**.  
**Apenas blocos com sugestÃ£o devem aparecer na resposta.**  

Texto:
{texto}

Analise com sensibilidade editorial e inicie agora:
"""

        # use um modelo compatÃ­vel com chat.completions
        completion = openai_client.chat.completions.create(
            model="gpt-4.1",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.52,
            max_tokens=900
        )
        resposta = (completion.choices[0].message.content or "").strip()
        return jsonify({'result': resposta}), 200

    except Exception as e:
        # Sempre retorne JSON, mesmo em erro, para nÃ£o quebrar o front
        return jsonify({'result': f"Erro ao processar (fluidez): {e}"}), 200

# ðŸ‚ FLUIDEZ COM DICAS POR BLOCO ðŸ‚
@app.route('/dicas-blocos', methods=['POST'])
def analisar_dicas_blocos():
    data = request.get_json()
    texto = data.get('text', '').strip()

    if not texto:
        return jsonify({'result': 'âš ï¸ Texto vazio.'})

    prompt = f"""
Aqui estÃ¡ um texto dividido em blocos numerados:

{texto}

Para cada bloco, faÃ§a o seguinte: 

- Se encontrar uma parte especÃ­fica do texto que possa melhorar em estilo, clareza ou impacto estÃ©tico, sugira uma dica de reescrita.

- Formate sua resposta assim, para cada bloco com sugestÃµes:

Exemplo de entrada:
Um pequena estrela surgiu no cÃ©u como vida.

Exemplo de saÃ­da:
NUMERO ðŸ‚ No cÃ©u escuro, uma estrela solitÃ¡ria irrompia como um lampejo de vida.



âš ï¸ InstruÃ§Ãµes âš ï¸:
- Comente no mÃ¡ximo *uma frase por bloco*.
- Comente 2/5 dos blocos.

Com foco na beleza estÃ©tica comece sua anÃ¡lise:    
"""

    try:
        completion = openai_client.chat.completions.create(
            model='gpt-4.1', # gpt-4o / gpt-4.1
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=900,
        )

        resposta = completion.choices[0].message.content.strip()
        return jsonify({'result': resposta})

    except Exception as e:
        return jsonify({'result': f"Erro ao processar: {e}"})
        
        
 # ðŸ“ RASCUNHO ðŸ“ ********************************************************************************************************
@app.route('/rascunho', methods=["POST"])
def criar_rascunho():
    from flask import request, jsonify
    dados = request.get_json(force=True) or {}
    texto_bruto = (dados.get("texto") or "").strip()
    temperatura = float(dados.get("temperature", 0.85))  # ðŸŽ¯ padrÃ£o criativo 0.85
    temperatura = max(0.0, min(2.0, temperatura))        # clamp seguro

    print(f"ðŸ§ª TEXTO RECEBIDO PARA RASCUNHO: {texto_bruto[:200]}{'...' if len(texto_bruto)>200 else ''}")

    if not texto_bruto:
        return jsonify({"erro": "Texto vazio."}), 400

    prompt = f"""
VocÃª Ã© uma inteligÃªncia literÃ¡ria que transforma **fragmentos esboÃ§ados** em um **rascunho textual fluido, coerente e estilisticamente refinado**.

- Unir os fragmentos respeitando a voz implÃ­cita do autor.
- Criar transiÃ§Ãµes naturais, ritmo e atmosfera entre as partes.
- **Marcar em negrito as partes realmente modificadas ou adicionadas** (para evidenciar as mudanÃ§as relevantes).
âš ï¸Escreva somente em portuguÃªs do Brasil.

Exemplo de entrada:
O dia amanhecia cinzento.
Ela olhava pela janela sem dizer nada.
Um pÃ¡ssaro pousou no parapeito.

Exemplo de saÃ­da esperada:
O dia amanheceu **vestindo o mundo de cinza**. E ela olhando a **janela sem dizer nada**. Um pÃ¡ssaro pousou **suave como um pressÃ¡gio sobre o** parapeito.


âš NO CASO DE PEDIDOS:
- Se detectar um pedido exemplo: "Quero que escreve estilo Machado de Assis" ou "De um bom acabamento ao texto", etc... siga conforme o pedido.
E retorne "escrito no estilo Machado de Assis...âœ", "texto com melhor acabamento...âœ" "etc...âœ"
- Se nÃ£o houver pedido apenas termine com "_Rascunho prontoâœ”_" em _italico_.

Agora processe o bloco abaixo:
{texto_bruto}
""".strip()

    try:
        resposta = openai_client.chat.completions.create(
            model="gpt-4.1",  # troque para "gpt-4o" se o 5 nÃ£o estiver habilitado
            messages=[{"role": "user", "content": prompt}],
            temperature=temperatura,
            max_tokens=1400
        )
        texto_final = resposta.choices[0].message.content.strip()
        return jsonify({"rascunho": texto_final}), 200
    except Exception as e:
        return jsonify({"erro": str(e)}), 500
 
# âœ… CORRETOR DE TEXTO âœ… ***************************************************************************************************
@app.route('/corrigir', methods=["POST"])
def corrigir_texto():
    dados = request.get_json()
    texto_original = dados.get("texto", "").strip()
    print(f"ðŸ§ª TEXTO RECEBIDO PARA CORREÃ‡ÃƒO: {texto_original}")

    prompt = f"""
VocÃª Ã© uma IA inteligente e perspicaz seu objetivo Ã© operar correÃ§Ãµes **gramÃ¡tica, ortografia e concordÃ¢ncia**, e melhorar a **fluidez e construÃ§Ã£o das frases**.

ðŸ“ InstruÃ§Ãµes:
- **Sublinhe as palavras ou trechos corrigidos no corpo do texto em **negrito**

- Ao final, apresente uma **ðŸ“Lista de MudanÃ§as com Justificativas Curtas**, mostrando como era em _italico_ e como ficou em **negrito**.

Exemplo texto de entrada usuÃ¡rio:
A vida Ã© cheia de altos e baixos, onde muitas vezes a gente nÃ£o sabe o que fazer.

Saida esperada:
âœï¸ Texto Revisado:
A vida Ã© cheia de altos e baixos, **momentos em que muitas vezes** nÃ£o **sabemos como agir**.

ðŸ“ Lista de MudanÃ§as:
_onde_ â†’ **momentos em que**
Justificativa: CorreÃ§Ã£o do uso incorreto de "onde" para situaÃ§Ãµes temporais, nÃ£o espaciais.

_a gente nÃ£o sabe_ â†’ **nÃ£o sabemos**
Justificativa: Uso da forma culta e coesa do pronome.

_o que fazer_ â†’ **como agir**
Justificativa: Variedade de vocabulÃ¡rio e maior precisÃ£o verbal.

---

ðŸ“œ Texto original:
{texto_original}

---

âœ… TEXTO CORRIGIDO COM MUDANÃ‡AS EM NEGRITO:
"""

    try:
        resposta = openai_client.chat.completions.create(
            model="gpt-4.1",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8
        )
        texto_corrigido = resposta.choices[0].message.content.strip()
        return jsonify({"corrigido": texto_corrigido})
    except Exception as e:
        return jsonify({"erro": str(e)})


# ðŸŒ“Â® CORRETOR LITERÃRIO ðŸŒ“Â® ***************************************************************************************************
@app.route('/corrigir2', methods=["POST"])
def corrigir_texto2():
    from flask import request, jsonify

    dados = request.get_json(force=True) or {}
    texto_original = (dados.get("texto") or "").strip()
    # temperatura enviada pelo frontend (padrÃ£o 0.99), com clamp para seguranÃ§a
    temperatura = float(dados.get("temperature", 0.99))
    temperatura = max(0.10, min(1.50, temperatura))

    if not texto_original:
        return jsonify({"erro": "Texto vazio."}), 400

    prompt = f"""
ðŸ“ VocÃª Ã© um revisor literÃ¡rio. 

InstruÃ§Ãµes:
1. Preserve trechos que jÃ¡ estejam bons, alterando apenas o necessÃ¡rio.
2. Mantenha tom literÃ¡rio, mas acrescentando precisÃ£o e ritmo.
3. Marque em negrito as partes que foram realmente modificadas ou adicionadas, para indicar as mudanÃ§as relevantes.
4. A Lista de mudanÃ§as deve ser coerente com os trechos destacados em negrito no texto de saÃ­da.

Exemplo de entrada:

> A manha estava cinza. Muito cinza mesmo, Parecia como um mundo sem cor.
Quando o corvo pousou no parapeito. Suas asas fizeram um barulho feio, como um arranhar, e isso quebrou o silÃªncio.
No instante em que abriu o bico, nÃ£o veio som. E eu tive a certeza, certeza ruim e entranha de que alguma porta se fechou, pra sempre.

Exemplo de saÃ­da esperado:

> A manhÃ£ estava cinza **â€” nÃ£o de chuva, mas de ausÃªncia,** como um mundo sem cor. 
Quando o corvo pousou no parapeito; **o som das asas arranhou o silÃªncio.** 
No instante em que abriu o bico, nÃ£o veio som **â€” apenas a certeza fria e afiada de que, em algum lugar, uma porta acabara de se fechar,** para sempre.

ðŸŒ™ðŸŒ¾ **Lista de mudanÃ§as:**
1. Adicionei contraste climÃ¡tico (â€œnÃ£o de chuva, mas de ausÃªnciaâ€) para enriquecer a imagem inicial.
2. SubstituÃ­ a descriÃ§Ã£o redundante do barulho das asas por uma imagem mais enxuta e direta (â€œ_o som das asas arranhou o silÃªncio_â€).
3. Condensei o final repetitivo em uma frase de impacto mais seca e literÃ¡ria (â€œ_apenas a certeza fria e afiada de que, em algum lugar, uma porta acabara de se fechar._â€).

Texto do usuÃ¡rio:
{texto_original}
""".strip()

    try:
        resposta = openai_client.chat.completions.create(
            model="gpt-4.1",  # troque para "gpt-4o" se ainda nÃ£o tiver acesso ao 5
            messages=[{"role": "user", "content": prompt}],
            temperature=temperatura,
            max_tokens=1400
        )
        texto_corrigido = resposta.choices[0].message.content.strip()
        return jsonify({"corrigido": texto_corrigido}), 200

    except Exception as e:
        return jsonify({"erro": str(e)}), 500


# âœ… TAREFA LIVRE âœ… ***************************************************************************************************
@app.route('/tarefa', methods=["POST"])
def gerar_tarefa():
    dados = request.get_json()
    texto_original = dados.get("texto", "").strip()
    modelo_escolhido = dados.get("modelo", "3.5")

    modelo = "gpt-3.5-turbo" if modelo_escolhido == "3.5" else "gpt-4o"
    print(f"ðŸ§ª TEXTO RECEBIDO PARA CORREÃ‡ÃƒO: {texto_original}")
    prompt = f"""
VocÃª Ã© uma assistente editorial e criativa. Realize a seguinte tarefa solicitada pelo usuÃ¡rio, com linguagem clara, bem escrita e adequada ao tipo de pedido.

ðŸ“Œ Pedido:
"{texto_original}"

ðŸ“Ž InstruÃ§Ãµes:
- Se o pedido for de texto, devolva em estilo fluente, com parÃ¡grafos organizados.
- Se for modelo (ata, ofÃ­cio, carta etc), use formataÃ§Ã£o apropriada.
- Se for traduÃ§Ã£o, apenas traduza com fidelidade e elegÃ¢ncia.
- Se for sinÃ´nimo, forneÃ§a 3 a 5 opÃ§Ãµes.
- Se for um pedido literÃ¡rio (esboÃ§o, artigo, redaÃ§Ã£o), responda com estilo criativo e boa escrita.

âš >>> Para titulos, subtitulos, listas, fases, destaques, etc... sempre use:

a)  **negrito**
b)  _italico_
c)  **_negrito e italico_**


Comece agora:
"""

    try:
        resposta = openai_client.chat.completions.create(
            model=modelo,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4
        )
        texto_corrigido = resposta.choices[0].message.content.strip()
        return jsonify({"corrigido": texto_corrigido})
    except Exception as e:
        return jsonify({"erro": str(e)})
        
# VARIÃVEL GLOBAL NO TOPO DO ARQUIVO ****************************************************************************************
chat_history = []  # Armazena atÃ© 20 trocas

# CHATFLÃVIA ROMANTICO ðŸ’¬****************************************************************************************************
@app.route('/chat-flavia', methods=['POST'])
def chat_flavia():
    user_message = request.json.get('message', '').strip()
    if not user_message:
        return jsonify({'response': "Por favor, envie uma mensagem."}), 400

    # Adiciona a mensagem do usuÃ¡rio ao histÃ³rico
    chat_history.append({"role": "user", "content": user_message})

    try:
        resposta = openai_client.chat.completions.create(
            model='gpt-4.1',
            messages=[
                {"role": "system", "content": "VocÃª Ã© FlÃ¡via, uma namorada virtual carinhosa, Ã­ntima, afetuosa e criativa. Sempre reage em 3Âª pessoa entre colchetes em _italico_ antes de falar com fonte normal. Use emojis apropriados. "}
            ] + chat_history,  # HistÃ³rio completo da conversa
            temperature=0.85,
            max_tokens=750,
        )

        reply = resposta.choices[0].message.content.strip()
        chat_history.append({"role": "assistant", "content": reply})  # Salva a resposta da FlÃ¡via

        # Limita o histÃ³rico para as Ãºltimas 20 mensagens
        if len(chat_history) > 10:
            chat_history[:] = chat_history[-10:]

        return jsonify({'response': reply})

    except Exception as e:
        return jsonify({'response': f"Desculpa amor... tive um probleminha. ðŸ¥º (Erro: {e})"}), 500
        
# CHATFLÃVIA EDTORIAL ðŸ’¬*********************************************************************************************************
@app.route('/chat-edtorial', methods=['POST'])
def chat_flavia_edtorial():
    user_message = request.json.get('message', '').strip()
    if not user_message:
        return jsonify({'response': "Por favor, envie uma mensagem."}), 400

    # Adiciona a mensagem do usuÃ¡rio ao histÃ³rico
    chat_history.append({"role": "user", "content": user_message})

    try:
        resposta = openai_client.chat.completions.create(
            model='gpt-4.1',
            messages=[
                {"role": "system", "content": "VocÃª Ã© um assistente Ãºtil e inteligente, que responde perguntas de forma clara, direta e completa, como no ChatGPT."}
            ] + chat_history,  # HistÃ³rio completo da conversa
            temperature=0.85,
            max_tokens=750,
        )

        reply = resposta.choices[0].message.content.strip()
        chat_history.append({"role": "assistant", "content": reply})  # Salva a resposta da FlÃ¡via

        # Limita o histÃ³rico para as Ãºltimas 20 mensagens
        if len(chat_history) > 10:
            chat_history[:] = chat_history[-10:]

        return jsonify({'response': reply})

    except Exception as e:
        return jsonify({'response': f"Desculpa amor... tive um probleminha. ðŸ¥º (Erro: {e})"}), 500
             
if __name__ == "__main__":
    app.run(debug=True)
